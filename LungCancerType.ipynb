{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colon_aca = 'lung_colon_image_set/colon_image_sets/colon_aca'\n",
    "colon_benign = 'lung_colon_image_set/colon_image_sets/colon_n'\n",
    "lung_aca = 'lung_colon_image_set/lung_image_sets/lung_aca'\n",
    "lung_benign = 'lung_colon_image_set/lung_image_sets/lung_n'\n",
    "lung_scc = 'lung_colon_image_set/lung_image_sets/lung_scc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resize_images(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            img = Image.open(file_path)\n",
    "            img = img.resize((224, 224))\n",
    "            img.save(file_path)\n",
    "            # print(f\"Resized and saved: {file_path}\")\n",
    "        except (OSError, IOError) as e:\n",
    "            print(f\"Skipping file: {file_path} due to error: {e}\")\n",
    "     \n",
    "# Resize images in each directory\n",
    "# resize_images(colon_aca)\n",
    "# resize_images(colon_benign)\n",
    "resize_images(lung_aca)\n",
    "resize_images(lung_benign)\n",
    "resize_images(lung_scc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_images(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = Image.open(folder + '\\\\' + filename)\n",
    "        img = np.array(img)\n",
    "        images.append(img)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "lung_aca_images = load_images(lung_aca)\n",
    "lung_benign_images = load_images(lung_benign)\n",
    "lung_scc_images = load_images(lung_scc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment data\n",
    "def dataAugmentation(images):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    datagen.fit(images)\n",
    "    return datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "def splitData(images):\n",
    "    x_train, x_test = train_test_split(images, test_size=0.2, random_state=42)\n",
    "    return x_train, x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lung_aca_datagen = dataAugmentation(lung_aca_images)\n",
    "lung_benign_datagen = dataAugmentation(lung_benign_images)\n",
    "lung_scc_datagen = dataAugmentation(lung_scc_images)\n",
    "\n",
    "lung_aca_train, lung_aca_test = splitData(lung_aca_images)\n",
    "lung_benign_train, lung_benign_test = splitData(lung_benign_images)\n",
    "lung_scc_train, lung_scc_test = splitData(lung_scc_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alici\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# use cnn to classify images\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Data Augmentation - rotate, shift, flip, zoom to prevent overfitting\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Improved Model Architecture: more layers, more filters, more neurons, diff activation functions\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(),\n",
    "            loss='categorical_crossentropy', \n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lung Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lung cancer model\n",
    "# put all the above code into one cell\n",
    "\n",
    "lung_aca_datagen = dataAugmentation(lung_aca_images)\n",
    "lung_benign_datagen = dataAugmentation(lung_benign_images)\n",
    "lung_scc_datagen = dataAugmentation(lung_scc_images)\n",
    "\n",
    "lung_aca_train, lung_aca_test = splitData(lung_aca_images)\n",
    "lung_benign_train, lung_benign_test = splitData(lung_benign_images)\n",
    "lung_scc_train, lung_scc_test = splitData(lung_scc_images)\n",
    "\n",
    "# combine datasets\n",
    "train_images = np.concatenate((lung_aca_train, lung_benign_train, lung_scc_train))\n",
    "test_images = np.concatenate((lung_aca_test, lung_benign_test, lung_scc_test))\n",
    "\n",
    "train_labels = np.concatenate((np.zeros(len(lung_aca_train)), np.ones(len(lung_benign_train)), np.full(len(lung_scc_train), 2)))\n",
    "test_labels = np.concatenate((np.zeros(len(lung_aca_test)), np.ones(len(lung_benign_test)), np.full(len(lung_scc_test), 2)))\n",
    "\n",
    "# one hot encoding\n",
    "train_labels = to_categorical(train_labels, 3)\n",
    "test_labels = to_categorical(test_labels, 3)\n",
    "\n",
    "print(\"Training images shape:\", train_images.shape)\n",
    "print(\"Training labels shape:\", train_labels.shape)\n",
    "print(\"Testing images shape:\", test_images.shape)\n",
    "print(\"Testing labels shape:\", test_labels.shape)\n",
    "print(\"Training images sample data:\", train_images[:1])\n",
    "print(\"Training labels sample data:\", train_labels[:1])\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "# Setup EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True  # Optionally restore model weights from the epoch with the best value of the monitored quantity.\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(test_images, test_labels),\n",
    "    callbacks=[early_stopping_monitor]  # Include EarlyStopping in the training phase\n",
    ")\n",
    "\n",
    "#test model\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "# predict\n",
    "predictions = model.predict(test_images)\n",
    "# get accuracy\n",
    "accuracy = np.mean(np.argmax(predictions, axis=1) == np.argmax(test_labels, axis=1))\n",
    "\n",
    "print(\"Accuracy percent: \", accuracy * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "model.save('lung_cancer_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
